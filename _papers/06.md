---
# Determines which paper appears first (lowest number (0) appears first)
sequence_id: 6

# Paper title
title: Optimal Dynamic Regret in LQR Control

# Accepted for oral presentation?
oral: 

# Paper authors
authors: Baby, Dheeraj*; Wang, Yu-Xiang


# Abstract for the papers
abstract: We consider the problem of nonstochastic control with a sequence of quadratic losses, i.e., LQR control. We provide an efficient online algorithm that achieves an optimal dynamic (policy) regret of $\tilde{O}(n^{1/3} \TV(M_{1:n}^{2/3}  \vee 1)$, where $\TV(M_{1:n})$ is the total variation of any oracle sequence of \emph{Disturbance Action} policies parameterized by $M_1,...,M_n$ --- chosen in hindsight to cater to unknown nonstationarity. The rate improves the best known rate of $\tilde{O}(\sqrt{n (\TV(M_{1:n})+1)} )$ for general convex losses and is information-theoretically optimal for LQR. Main technical components include the reduction of LQR to online linear regression with delayed feedback due to Foster and Simchowitz 2020, as well as a new \emph{proper} learning algorithm with an optimal $\tilde{O}(n^{1/3})$ dynamic regret on a family of ``minibatched'' quadratic losses, which could be of independent interest.

# Talk video (only the video id; i.e., string following https://youtu.be/)
youtube: 
drive2: https://www.youtube.com/watch?v=r4qvEbyFmJM

pdf: 06.pdf

poster: 06.pdf
---
