---
# Determines which paper appears first (lowest number (0) appears first)
sequence_id: 39

# Paper title
title: Machine Learning Explainability & Fairness - Insights from Consumer Lending

# Accepted for oral presentation?
oral: 

# Abstract for the papers
abstract: An ongoing debate in the credit lending domain is whether lenders and regulators can responsibly use machine learning models. Transparency is a major concern in this area, but machine learning models can be difficult to interpret. Our work is a case study of the models and explainability tools currently in use in the finance industry that advertise better transparency. In this submission we focus on the effects of the explainability tools on disparate impact / fair lending in credit underwriting. We evaluate these explainability tools on a criteria we dub Òusability,Ó which indicates a toolÕs ability to identify less discriminatory alternative models. Notably, we find that in the context of credit lending, the intuitive method of feature dropping, which attempts to reduce bias by removing ÒproblematicÓ features, does not lead to less discriminatory alternative models, and often leads to substantial performance deterioration. In contrast, automated tools that search for a range of less discriminatory alternative models can successfully improve fairness metrics. The findings presented here are a subset of results from a larger study "Machine Learning Explainability & Fairness - Insights from Consumer Lending". In the full report we investigate several other aspects of ML in financial services, including the use of explainability tools in Adverse Action Notices. 


# Paper authors
authors: Yazdi, Sormeh*; Blattner, Laura; McElfresh, Duncan; Stark, P-R; Spiess, Jann L

 

# Talk video (only the video id; i.e., string following https://youtu.be/)
youtube: CQdCwS99ka8
drive:
drive2:

pdf: 39.pdf

poster:  
---
