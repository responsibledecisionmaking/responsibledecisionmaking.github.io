---
# Determines which paper appears first (lowest number (0) appears first)
sequence_id: 43

# Paper title
title: LPI -  Learned Positional Invariances for Transfer of Task Structure and Zero-shot Planning

# Accepted for oral presentation?
oral: 

# Abstract for the papers
abstract: Real-world tasks often include interactions with the environment where an agent's actions can drastically change the available or desirable long-term outcomes. One formulation of this in the reinforcement learning setting is in terms of non-Markovian rewards, where the reward function, and thus the available rewards, are themselves history-dependent, and dynamically change given the agent-environment interactions. An important challenge for navigating such environments is to be able to capture the structure of this dynamic reward function in a way that is interpretable and allows for optimal planning.  This structure, in conjunction with the particular task setting at hand, can determine the optimal order in which actions should executed or subtasks completed, however, planning methods face the challenge of combinatorial explosion if all such orderings need to be evaluated. Learning invariances inherent in the task structure can alleviate this pressure, allowing the planning method to recognise task segments where temporal ordering is irrelevant for predicting outcomes downstream. To enable this efficiency in planning, we simultaneously train a model to segment a task and track the changing reward function that results from the agent√ïs actions, while also learning about the permutation invariances relevant for this prediction, allowing zero-shot or few-shot generalisation for complex, dynamic reinforcement learning tasks.

# Paper authors
authors: Madarasz, Tamas J*

 

# Talk video (only the video id; i.e., string following https://youtu.be/)
youtube: 
drive:
drive2: https://drive.google.com/file/d/10z8ePKhDQb1GFsMdLdPdub15l_ifjM0f/view?usp=sharing

pdf: 43.pdf

poster:  
---
