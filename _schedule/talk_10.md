---
sequence_id: 10
speaker: Solon Barocas
title: Explanations in Whose Interests?
time: 1430
#affil: 
webpage: http://solon.barocas.org/
abstract: In the United States, the law requires that lenders explain their adverse decisions to consumers, one goal of which is to educate consumers about how to receive more favorable decisions in the future. Scholars have recently proposed a range of new techniques to help lenders realize this goal when their decision making relies on machine learning. However, attempts to directly map these techniques onto applications in finance are often somewhat stylized, failing to take into account important aspects of lending in practice. Lending decisions are rarely binary (i.e., lend/don't lend). Machine learning models are often used by lenders to estimate consumers' risk of default, not to classify applicants as creditworthy or not; these estimates of risk inform a more complex decision about the terms on which lenders are willing to grant credit to consumers. Differences in the terms of a loan often result in very different utility for consumers and lenders. In fact, access to credit on unfavorable terms can be actively harmful to consumers, even if it might be profitable for lenders. Very little of the existing scholarship on explainable AI in finance---or that uses lending as a motivating example---takes these crucial details into account. As a result, many of the proposed methods for explaining adverse lending decisions may not help consumers achieve better outcomes---and may even harm them in some cases. 
---